{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGb+5FXAXljK3p/2gbc1Os",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-ferry/cs676-fall-2025/blob/main/project-1/deliverable1/deliverable1v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xe5eilhi2W5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credibility Scoring for eBay Soccer Card Listings in a RAG Chatbot"
      ],
      "metadata": {
        "id": "KjTKFJpkYRUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract\n",
        "We propose and evaluate a credibility scoring component for a Retrieval-Augmented Generation (RAG) chatbot that surfaces soccer card listings from eBay.  The system assigns a per-URL credibility score to help users judge the reliability of cited sources and prioritize higher-quality listing.  Our approach is hybrid: a transparent rule-based layer (domain/transport, content heuristics, and eBay-specific seller/listing signals) plus a lighweight ML calibration (logistic regression) that learns to reweight signal from labeled data.  We present the prototype algorithm, a stable JSON API, initial experiment and roadmap to production."
      ],
      "metadata": {
        "id": "e14kF-ssYays"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVGIARFGZ_XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction & Scope\n",
        "Large language models augemented with retrieval (RAG) can cite live source for pricing, comps, and context.  However, cited sources vary in reliability.  For sports cards on marketplaces like eBay, credibility as the likelihood that a liting accurately respresents what it claims (authenticity, condition clarity, seller reliability, sufficient evidence) and that it's a solid source to support chatbot responses.\n",
        "\n",
        "The report describes the design and evaluation of a credibility scorer that:\n",
        "\n",
        "\n",
        "*   Takes a URL as input\n",
        "*   Computes interpretable signals (domain prior seller feedback %, returns policy, specific/keywords, etc)\n",
        "*   Aggregates them into a 0-100 score, optionally calibrated via a small supervised model\n",
        "*   Returns a stable JSON the chatbot can display alongside citations.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KtgLxsB3YbgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Problem Framing\n",
        "Goal: Assign each listing a credibility score useful for ranking and for user-facing explanation.\n",
        "\n",
        "Assumption:\n",
        "\n",
        "\n",
        "*   Seller reputation (feedback %, count, Top Rated) correlates with trust.\n",
        "*   Listings with clear photos, specific card attributes (grade, serial, set), and return policies are more reliable\n",
        "*   Very short or ambiguous descriptions reduce credibility\n",
        "*   Sentiment terms can be a weak prior (e.g. \"creased\", \"OC\", \"gem\", \"clean\")\n",
        "\n",
        "Next-steps:  We do not yet authenticate PSA certs, verify images, or compute fair market value.  These are roadmap items."
      ],
      "metadata": {
        "id": "fepTJ8DbafsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & Config\n",
        "\n",
        "# Purpose of this cell:\n",
        "# - Import only what we need for the core prototype to keep fast and stable\n",
        "# - Set conservaitve network defaults (timeouts/headers) so production integration goes smoother.\n",
        "# - Pre-compile a domain regex for eBay to enable platform-specific signals later.\n",
        "\n",
        "from __future__ import annotations\n",
        "# ^ Enables \"forward references\" for type hints (e.g., using a class/type name before it's defined)\n",
        "# Helps keep the file order flexible\n",
        "\n",
        "import dataclasses\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import typing as t\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timezone\n",
        "from urllib.parse import urlparse\n",
        "# ^ Standard-library imports only so far:\n",
        "# - cataclasses/dataclass: simple typed containers for signals and score results\n",
        "# - json: for serializing output/dicts\n",
        "# - math: numeric helpers (Log10, exp for squashing function)\n",
        "# - re: regular expressions for parsing text/html heuristics\n",
        "# - time: peformance timing (ms) for basic benchmarking/metadata\n",
        "# - typing: type hints, e.g., t.Sequence[float]\n",
        "# - datetime/timezone: timestamps in UTC (stable logging and reproducability)\n",
        "# - urllib.parse.urlparse: strict URL validation and parsing\n",
        "\n",
        "# Optional imports guarded at runtime; keep import-time light and notebook robust.\n",
        "try:\n",
        "    import requests  # HTTP client used only when dry_run=False\n",
        "except Exception:\n",
        "    requests = None  # # If requests isn't available (or blocked), we degrade gracefully.\n",
        "# ^ Rationale: Deliverable 1 must run even without network access (e.g., in Colab or CI).\n",
        "#   The code uses a \"dry_run\" mode that synthesizes HTML; this keeps tests deterministic.\n",
        "\n",
        "# Optional libs used later (pandas for tables; sklearn for D2 calibration)\n",
        "try:\n",
        "    import pandas as pd  # tabular display and simple data wrangling for ranked outputs\n",
        "except Exception:\n",
        "    pd = None # Allow notebook to run even if pandas isn't installed.\n",
        "\n",
        "try:\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import numpy as np\n",
        "except Exception:\n",
        "    LogisticRegression = None\n",
        "    Pipeline = None\n",
        "    StandardScaler = None\n",
        "    train_test_split = None\n",
        "    np = None\n",
        "\n",
        "# --- Network defaults (used only if dry_run=False) ---\n",
        "DEFAULT_TIMEOUT_S = 6.0\n",
        "# ^ Per-request timeout (seconds).  Conservative to avoid hanging UI calls.\n",
        "\n",
        "DEFAULT_HEADERS = {\n",
        "    # Custom UA string: polite + traceable in server logs; helps avoid some bot blocks.\n",
        "    \"User-Agent\": \"CredScorer/0.1 (+https://example.edu/project)\",\n",
        "    # Accept header: prefer HTML/XML; still accept anything to be resilient.\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "}\n",
        "\n",
        "# --- Platform detector (precompiled regex) ---\n",
        "# Matches eBay primary domain and common regional TLDs (ebay.com, ebay.co.uk, ebay.de, etc.).\n",
        "EbayLike = re.compile(r\"(^|\\.)ebay\\.(com|co\\.[a-z]{2}|[a-z]{2})$\", re.I)\n"
      ],
      "metadata": {
        "id": "BjSRhuQfzrQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f9_HjzBHcOZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 - Data Structures & Stable Response Schema\n",
        "# -------------------------------------------------\n",
        "# Purpose\n",
        "# 1) Define small, typed containers for signals and results (using dataclasses).\n",
        "# 2) Provide a *single stable* JSON contract via 'response_json(...)' that every caller can rely on\n",
        "#    This avoids brittle “if error, shape is different” problems when we integrate (Deliverable 3)\n",
        "\n",
        "@dataclass\n",
        "class Signal:\n",
        "\"\"\"\n",
        "    An interpretable scoring *component* (feature) contributing to credibility.\n",
        "\n",
        "    Fields\n",
        "    ------\n",
        "    name : str\n",
        "        Short identifier (e.g., \"domain_prior\", \"seller_feedback_pct\").\n",
        "    value : float\n",
        "        Normalized feature value in [0, 1]. Higher is better (more credible/desirable).\n",
        "    weight : float\n",
        "        Weight in [0, 1] reflecting this signal's *influence* in the current heuristic model.\n",
        "        (In Deliverable 2, a learned model can reweight via calibration.)\n",
        "    rationale : str\n",
        "        Human-readable explanation so the UI/report can show *why* a score moved.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    value: float   # 0..1\n",
        "    weight: float  # 0..1\n",
        "    rationale: str\n",
        "\n",
        "    def contribution(self) -> float:\n",
        "              \"\"\"\n",
        "        Weighted contribution for this signal.\n",
        "        We keep the math simple and transparent: contribution = value * weight.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Contribution in [0, 1] (typically small), later aggregated and squashed to [0, 100].\n",
        "        \"\"\"\n",
        "\n",
        "        return self.value * self.weight\n",
        "@dataclass\n",
        "class ScoreResult:\n",
        "\"\"\"\n",
        "    Internal container for an entire scoring run on a single URL.\n",
        "    We keep this separate from the external JSON payload so we can evolve internals\n",
        "    without breaking the API contract.\n",
        "\n",
        "    Fields\n",
        "    ------\n",
        "    url : str\n",
        "        The URL that was evaluated.\n",
        "    status : str\n",
        "        \"ok\" for success; or \"invalid_url\", \"fetch_error\", etc. for graceful failure modes.\n",
        "    score_abs : float\n",
        "        Absolute score after aggregation and squashing to [0, 100].\n",
        "    score_pct : float | None\n",
        "        Optional percentile vs a cohort (if provided by batch ranking).\n",
        "    signals : list[Signal]\n",
        "        All computed signals with values/weights and rationales.\n",
        "    errors : list[str]\n",
        "        Non-fatal errors/warnings encountered (e.g., network timeouts).\n",
        "    meta : dict[str, t.Any]\n",
        "        Extra metadata (host, is_ebay flag, timestamps, timings, version tag).\n",
        "    \"\"\"\n",
        "    url: str\n",
        "    status: str\n",
        "    score_abs: float\n",
        "    score_pct: float | None\n",
        "    signals: list[Signal]\n",
        "    errors: list[str]\n",
        "    meta: dict[str, t.Any]\n",
        "\n",
        "def response_json(result: ScoreResult) -> dict:\n",
        "    \"\"\"\n",
        "    Convert internal ScoreResult into a *stable* JSON/dict that clients can consume.\n",
        "    This is the public contract for Deliverable 1/2/3. Keep this structure stable.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        {\n",
        "          \"url\": <str>,\n",
        "          \"status\": <\"ok\" | \"invalid_url\" | \"fetch_error\" | ...>,\n",
        "          \"score\": {\"absolute\": <float 0..100>, \"percentile\": <float|None>},\n",
        "          \"signals\": [{\"name\":..., \"value\":..., \"weight\":..., \"rationale\":...}, ...],\n",
        "          \"errors\": [<str>, ...],\n",
        "          \"meta\": { \"host\":..., \"is_ebay\":..., \"fetched_at\":..., \"elapsed_ms\":..., \"fetch_ms\":..., \"version\":\"d1-0.1\" }\n",
        "        }\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"url\": result.url,\n",
        "        \"status\": result.status,\n",
        "        \"score\": {\"absolute\": result.score_abs, \"percentile\": result.score_pct},\n",
        "        \"signals\": [dataclasses.asdict(s) for s in result.signals],\n",
        "        \"errors\": result.errors,\n",
        "        \"meta\": result.meta,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "mFmtQDti0Cj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 - Utilities\n",
        "# -------------------\n",
        "# Purpose: small helpers that are used everywhere else\n",
        "# Keep them fast, deterministic, and side-effect free\n",
        "\n",
        "\n",
        "\n",
        "def _cheap_text(html: str) -> str:\n",
        "  \"\"\"\n",
        "\n",
        "  Ultra-Fast HTML > text stripper for heuristics\n",
        "  Avoid BeautifulSoup to keep dependencies light and speed high.\n",
        "\n",
        "  Steps:\n",
        "    1) Remove <script> and <style> blocks (noise).\n",
        "    2) Remove all remaining HTML tags.\n",
        "    3) Collapse whitespace to single spaces.\n",
        "  Returns a plain text string suitable for regex/keyword scans.\n",
        "  \"\"\"\n",
        "    text = re.sub(r\"<script[\\s\\S]*?</script>\", \" \", html, flags=re.I)\n",
        "    text = re.sub(r\"<style[\\s\\S]*?</style>\", \" \", text, flags=re.I)\n",
        "    text = re.sub(r\"<[^>]+>\", \" \", text)          # strip tags\n",
        "    text = re.sub(r\"\\s+\", \" \", text)              # normalize whitespace\n",
        "    return text.strip()\n",
        "\n",
        "def _squash_0_100(raw: float) -> float:\n",
        "    \"\"\"\n",
        "    Map an unbound-ish raw sum of contributions to a user-friendly 0..100 score\n",
        "    using a smooth logistic curve.  Center around ~0.8 (moderate sum), so small\n",
        "    changes near the center are visible but extremes saturate.\n",
        "\n",
        "    raw: float, typically ~0..1.4 (sum of value*weight across signals)\n",
        "    \"\"\"\n",
        "    # Smooth logistic squashing to [0,100], centered around ~0.8\n",
        "    x = raw - 0.8\n",
        "    sig = 1 / (1 + math.exp(-3.5 * x))\n",
        "    return round(100 * sig, 2)\n",
        "\n",
        "def _percentile(x: float, arr: list[float]) -> float:\n",
        "    \"\"\"\n",
        "    Inclusive rank percentile in 0..100.  If arr is empty, returns NaN.\n",
        "    We use a simple <= rank so ties are included.\n",
        "    \"\"\"\n",
        "    if not arr:\n",
        "        return float(\"nan\")\n",
        "    rank = sum(1 for a in arr if a <= x)\n",
        "    return round(100 * rank / len(arr), 2)\n",
        "\n",
        "def _now_iso() -> str:\n",
        "    \"\"\"UTC timestamp in ISO-8601 for reproducible logs/metadata.\"\"\"\n",
        "    return datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "def _elapsed_ms(t0: float) -> int:\n",
        "    \"\"\"Milliseconds elapsed since montonic start to (from time.perf_counter()).\"\"\"\n",
        "    return int((time.perf_counter() - t0) * 1000)\n",
        "\n",
        "def _synthetic_page_for(host: str) -> str:\n",
        "    \"\"\"Deterministic synthetic HTML used by dry_run=True.\n",
        "    We emit and eBay-like snippet for eBay hosts, and a generic article otherwise.\"\"\"\n",
        "    if EbayLike.search(host or \"\"):\n",
        "        return (\n",
        "            \"<html><head><title>eBay Listing</title></head><body>\"\n",
        "            \"Top Rated Seller (99.7% positive feedback) (12450) feedback. \"\n",
        "            \"2024 Topps Chrome UEFA Refractor PSA 10 Rookie /99 auto. \"\n",
        "            \"Ships from New York. 30 day returns. \"\n",
        "            \"<img/><img/><img/><img/><img/><img/>\"\n",
        "            \"</body></html>\"\n",
        "        )\n",
        "    return (\n",
        "        \"<html><body>By John Doe. Published 2023. \"\n",
        "        \"References: https://doi.org/10.x/y \"\n",
        "        \"This is a sample article body with some length and structure.\"\n",
        "        \"</body></html>\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "fPl4BW830MI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - Generic, platform-agnostic signals\n",
        "# -------------------------------------------------------\n",
        "# These signals work for *any* URL and provide a transparent baseline.\n",
        "\n",
        "from typing import List\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# Reuse the Signal class from Cell 2\n",
        "# from your_module import Signal  # (already defined in notebook)\n",
        "\n",
        "def _signal_domain_baseline(host: str) -> Signal:\n",
        "    \"\"\"\n",
        "    Small, interpretable prior based on the host's TLD/category.\n",
        "    Rationale: Certain domains (gov/edu) tend to have stronger editorial standards,\n",
        "    while eBay is a known marketplace with established buyer protections.\n",
        "    \"\"\"\n",
        "    h = (host or \"\").lower()\n",
        "    if h.endswith(\".gov\") or h.endswith(\".edu\"):\n",
        "        return Signal(\"domain_prior\", 0.90, 0.10, \"Academic/Gov domain prior\")\n",
        "    if h.endswith(\".org\"):\n",
        "        return Signal(\"domain_prior\", 0.75, 0.08, \".org prior (neutral-to-positive)\")\n",
        "    # Note: eBay handled again in eBay-specific signals, but we include a modest prior here.\n",
        "    from re import compile, I\n",
        "    if compile(r\"(^|\\.)ebay\\.(com|co\\.[a-z]{2}|[a-z]{2})$\", I).search(h):\n",
        "        return Signal(\"domain_prior\", 0.70, 0.10, \"Trusted marketplace host (eBay)\")\n",
        "    if h.endswith(\".com\"):\n",
        "        return Signal(\"domain_prior\", 0.60, 0.07, \".com baseline prior\")\n",
        "    return Signal(\"domain_prior\", 0.45, 0.05, \"Unknown/low-signal domain\")\n",
        "\n",
        "def _signal_transport_security(scheme: str) -> Signal:\n",
        "    \"\"\"\n",
        "    HTTPS is a soft trust signal (tamper-resistance in transit, modern hosting).\n",
        "    We don't over-weight it; just nudge up if https, down if http.\n",
        "    \"\"\"\n",
        "    return Signal(\n",
        "        \"https\",\n",
        "        1.0 if scheme == \"https\" else 0.4,\n",
        "        0.04,\n",
        "        \"HTTPS vs HTTP transport\",\n",
        "    )\n",
        "\n",
        "def _signals_content_quality(html: str) -> List[Signal]:\n",
        "    \"\"\"\n",
        "    Very lightweight text-based heuristics:\n",
        "      - Content length band (too short is suspect; too long is noisy).\n",
        "      - Outbound links/citations density (hints at sourcing).\n",
        "      - Author/date phrase hint (weak proxy for structured content).\n",
        "    These are intentionally conservative and interpretable.\n",
        "    \"\"\"\n",
        "    s: List[Signal] = []\n",
        "    text = _cheap_text(html)\n",
        "    n = len(text.split())\n",
        "\n",
        "    # Length band\n",
        "    if n <= 30:\n",
        "        v, why = 0.20, \"Very short body\"\n",
        "    elif n <= 120:\n",
        "        v, why = 0.55, \"Short body\"\n",
        "    elif n <= 2500:\n",
        "        v, why = 0.80, \"Reasonable body length\"\n",
        "    else:\n",
        "        v, why = 0.60, \"Very long body (diminishing returns)\"\n",
        "    s.append(Signal(\"content_length\", v, 0.07, why))\n",
        "\n",
        "    # Outbound refs/links density\n",
        "    cites = len(re.findall(r\"(doi\\.org/|https?://)\\S+\", text))\n",
        "    s.append(Signal(\"citations_links\", min(cites / 5, 1.0), 0.04, \"Outbound refs/links density\"))\n",
        "\n",
        "    # Author/date hint\n",
        "    has_authorish = bool(re.search(r\"\\bby\\s+[A-Z][a-z]+\", text))\n",
        "    s.append(Signal(\"author_block_hint\", 1.0 if has_authorish else 0.5, 0.03, \"Author/date block hints\"))\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "WwG_ZkO40Q1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 -\n",
        "\n",
        "# Hobby lexicons (expand later as needed)\n",
        "CARD_TERMS = {\n",
        "    # Rookie cues & desirability\n",
        "    \"rookie\": 0.12, \"rc\": 0.08,\n",
        "    # Grading\n",
        "    \"psa 10\": 0.16, \"bgs 9.5\": 0.10, \"sgc 10\": 0.08, \"gem mint\": 0.12,\n",
        "    # Auto/serial\n",
        "    \"auto\": 0.12, \"autograph\": 0.12, \"/\": 0.10,  # /10, /25...\n",
        "    # Sets/variants\n",
        "    \"refractor\": 0.08, \"color match\": 0.10, \"prizm\": 0.08,\n",
        "    \"topps\": 0.06, \"merlin\": 0.06, \"select\": 0.06, \"optic\": 0.06,\n",
        "}\n",
        "\n",
        "_POS = {\n",
        "    \"grail\",\"pc\",\"beautiful\",\"clean\",\"crisp\",\"gem\",\"iconic\",\n",
        "    \"undervalued\",\"deal\",\"bargain\",\"goat\",\"legend\",\"heat\",\n",
        "}\n",
        "_NEG = {\n",
        "    \"creased\",\"damage\",\"ding\",\"scratches\",\"scratched\",\"off-center\",\n",
        "    \"offcenter\",\"trimmed\",\"fake\",\"reprint\",\"altered\",\"stain\",\n",
        "    \"worst\",\"overpriced\",\n",
        "}\n",
        "\n",
        "def sentiment_features(text: str) -> list[Signal]:\n",
        "    tokens = re.findall(r\"[a-zA-Z\\-]+\", text.lower())\n",
        "    pos_hits = sum(1 for w in tokens if w in _POS)\n",
        "    neg_hits = sum(1 for w in tokens if w in _NEG)\n",
        "    total = max(pos_hits + neg_hits, 1)\n",
        "    polarity = (pos_hits - neg_hits) / total  # [-1,1]\n",
        "    val = (polarity + 1) / 2                  # [0,1]\n",
        "    return [Signal(\"sentiment\", val, 0.05, f\"lexicon polarity {polarity:.2f}\")]\n",
        "\n",
        "def _signals_ebay_listing(html: str) -> list[Signal]:\n",
        "    s: list[Signal] = []\n",
        "    text = _cheap_text(html)\n",
        "    lower = text.lower()\n",
        "\n",
        "    # Sentiment (modest weight, interpretable)\n",
        "    s.extend(sentiment_features(text))\n",
        "\n",
        "    # Seller feedback %\n",
        "    m = re.search(r\"(\\d{1,3}\\.\\d)\\%\\s*positive feedback\", text, re.I)\n",
        "    if m:\n",
        "        pct = float(m.group(1))\n",
        "        v = 0.2 + 0.8*(pct/100.0)\n",
        "        s.append(Signal(\"seller_feedback_pct\", min(v,1.0), 0.12, f\"Seller feedback {pct}%\"))\n",
        "    else:\n",
        "        s.append(Signal(\"seller_feedback_pct\", 0.55, 0.06, \"Feedback % not found\"))\n",
        "\n",
        "    # Feedback count (log scale)\n",
        "    m2 = re.search(r\"\\((\\d{2,6})\\)\\s*feedback\", text, re.I)\n",
        "    if m2:\n",
        "        cnt = int(m2.group(1))\n",
        "        v = min(math.log10(max(cnt,1))/5.0 + 0.4, 1.0)\n",
        "        s.append(Signal(\"seller_feedback_count\", v, 0.08, f\"Feedback count {cnt}\"))\n",
        "\n",
        "    # Top Rated Seller\n",
        "    if re.search(r\"top rated seller\", text, re.I):\n",
        "        s.append(Signal(\"top_rated\", 1.0, 0.06, \"Top Rated Seller badge\"))\n",
        "\n",
        "    # Return policy\n",
        "    if re.search(r\"\\b(30|60)\\s*day returns?\\b\", text, re.I):\n",
        "        s.append(Signal(\"returns_policy\", 0.92, 0.05, \"30/60-day returns\"))\n",
        "    elif re.search(r\"no returns\", text, re.I):\n",
        "        s.append(Signal(\"returns_policy\", 0.50, 0.05, \"No returns\"))\n",
        "\n",
        "    # Specificity score (keywords + jersey number hint)\n",
        "    term_score = 0.0\n",
        "    for k, w in CARD_TERMS.items():\n",
        "        if k in lower:\n",
        "            term_score += w\n",
        "    if re.search(r\"\\b#?\\d{1,2}\\b\", lower):\n",
        "        term_score += 0.04\n",
        "    term_score = min(term_score, 1.0)\n",
        "    s.append(Signal(\"card_specificity_terms\", term_score, 0.14, \"Hobby keywords present\"))\n",
        "\n",
        "    # Year + Set\n",
        "    any_year = bool(re.search(r\"\\b(19|20)\\d{2}\\b\", text))\n",
        "    any_set  = bool(re.search(r\"(prizm|topps|merlin|select|optic|megacracks|chrome)\", lower))\n",
        "    s.append(Signal(\"year_set_hint\", 1.0 if (any_year and any_set) else 0.6, 0.06, \"Year+Set mentioned\"))\n",
        "\n",
        "    # Image count (thoroughness proxy)\n",
        "    imgs = len(re.findall(r\"<img\\b\", html, re.I))\n",
        "    if imgs >= 8:\n",
        "        s.append(Signal(\"image_count\", 0.95, 0.05, f\"{imgs} images\"))\n",
        "    elif imgs >= 4:\n",
        "        s.append(Signal(\"image_count\", 0.75, 0.05, f\"{imgs} images\"))\n",
        "    else:\n",
        "        s.append(Signal(\"image_count\", 0.55, 0.05, f\"{imgs} images\"))\n",
        "\n",
        "    # Shipping hint\n",
        "    if re.search(r\"ships from\\s+[A-Za-z ]+\", lower):\n",
        "        s.append(Signal(\"shipping_from\", 0.70, 0.03, \"Ships-from present\"))\n",
        "\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "ZDKqUzMO0UFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 -\n",
        "\n",
        "def score_url(\n",
        "    url: str,\n",
        "    *,\n",
        "    dry_run: bool = False,\n",
        "    cohort_scores: t.Sequence[float] | None = None,\n",
        "    session: t.Any | None = None,\n",
        ") -> dict:\n",
        "    \"\"\"Evaluate a reference URL and return structured credibility JSON.\"\"\"\n",
        "    t0 = time.perf_counter()\n",
        "    errors: list[str] = []\n",
        "    signals: list[Signal] = []\n",
        "\n",
        "    # 1) URL validation\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if parsed.scheme not in {\"http\", \"https\"} or not parsed.netloc:\n",
        "            raise ValueError(\"URL must include http(s) scheme and host\")\n",
        "        host = parsed.hostname or \"\"\n",
        "    except Exception as e:\n",
        "        result = ScoreResult(\n",
        "            url=url, status=\"invalid_url\",\n",
        "            score_abs=0.0, score_pct=None, signals=[],\n",
        "            errors=[f\"invalid_url: {e}\"],\n",
        "            meta={\"fetched_at\": _now_iso(), \"elapsed_ms\": _elapsed_ms(t0)},\n",
        "        )\n",
        "        return response_json(result)\n",
        "\n",
        "    # 2) Domain/transport priors\n",
        "    signals.append(_signal_domain_baseline(host))\n",
        "    signals.append(_signal_transport_security(parsed.scheme))\n",
        "\n",
        "    # 3) Fetch or synthesize\n",
        "    html: str | None = None\n",
        "    status: str = \"ok\"\n",
        "    fetched_ms = None\n",
        "    if dry_run:\n",
        "        html = _synthetic_page_for(host)\n",
        "        fetched_ms = _elapsed_ms(t0)\n",
        "    else:\n",
        "        if requests is None:\n",
        "            errors.append(\"requests_not_available\")\n",
        "            status = \"fetch_error\"\n",
        "        else:\n",
        "            try:\n",
        "                sess = session or requests.Session()\n",
        "                r = sess.get(url, headers=DEFAULT_HEADERS, timeout=DEFAULT_TIMEOUT_S)\n",
        "                fetched_ms = _elapsed_ms(t0)\n",
        "                if r.status_code >= 400:\n",
        "                    raise RuntimeError(f\"HTTP {r.status_code}\")\n",
        "                html = r.text\n",
        "            except Exception as e:\n",
        "                errors.append(f\"fetch_error: {e}\")\n",
        "                status = \"fetch_error\"\n",
        "\n",
        "    # 4) Content & platform signals\n",
        "    if html:\n",
        "        try:\n",
        "            signals.extend(_signals_content_quality(html))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"content_parse_error: {e}\")\n",
        "        try:\n",
        "            if EbayLike.search(host or \"\"):\n",
        "                signals.extend(_signals_ebay_listing(html))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"ebay_parse_error: {e}\")\n",
        "\n",
        "    # 5) Aggregate\n",
        "    raw = sum(s.contribution() for s in signals)\n",
        "    abs_score = _squash_0_100(raw)\n",
        "\n",
        "    # 6) Optional percentile vs cohort\n",
        "    pct = None\n",
        "    if cohort_scores:\n",
        "        try:\n",
        "            pct = _percentile(abs_score, list(cohort_scores))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"percentile_error: {e}\")\n",
        "\n",
        "    # 7) Unified JSON\n",
        "    result = ScoreResult(\n",
        "        url=url, status=status,\n",
        "        score_abs=abs_score, score_pct=pct,\n",
        "        signals=signals, errors=errors,\n",
        "        meta={\n",
        "            \"host\": host,\n",
        "            \"is_ebay\": bool(EbayLike.search(host or \"\")),\n",
        "            \"fetched_at\": _now_iso(),\n",
        "            \"elapsed_ms\": _elapsed_ms(t0),\n",
        "            \"fetch_ms\": fetched_ms,\n",
        "            \"version\": \"d1-0.1\",\n",
        "        },\n",
        "    )\n",
        "    return response_json(result)\n",
        "\n",
        "def rank_listings(urls: list[str], *, dry_run: bool = False) -> list[dict]:\n",
        "    \"\"\"Score a list of URLs and return rows sorted by absolute score desc.\"\"\"\n",
        "    rows: list[dict] = []\n",
        "    sess = None if dry_run else (requests.Session() if requests else None)\n",
        "\n",
        "    abs_scores: list[float] = []\n",
        "    tmp: list[dict] = []\n",
        "    for u in urls:\n",
        "        r = score_url(u, dry_run=dry_run, session=sess)\n",
        "        tmp.append(r)\n",
        "        abs_scores.append(r[\"score\"][\"absolute\"])\n",
        "\n",
        "    for r in tmp:\n",
        "        r[\"score\"][\"percentile\"] = _percentile(r[\"score\"][\"absolute\"], abs_scores)\n",
        "        rows.append(r)\n",
        "\n",
        "    rows.sort(key=lambda d: d[\"score\"][\"absolute\"], reverse=True)\n",
        "    return rows\n",
        "\n",
        "def to_dataframe(rows: list[dict]):\n",
        "    if pd is None:\n",
        "        raise RuntimeError(\"pandas not installed\")\n",
        "    flat = []\n",
        "    for r in rows:\n",
        "        base = {\n",
        "            \"url\": r[\"url\"],\n",
        "            \"score_abs\": r[\"score\"][\"absolute\"],\n",
        "            \"score_pct\": r[\"score\"].get(\"percentile\"),\n",
        "            \"status\": r[\"status\"],\n",
        "            \"host\": r[\"meta\"].get(\"host\"),\n",
        "            \"is_ebay\": r[\"meta\"].get(\"is_ebay\"),\n",
        "        }\n",
        "        for sig in r[\"signals\"]:\n",
        "            base[f\"sig_{sig['name']}\"] = sig[\"value\"] * sig[\"weight\"]\n",
        "        flat.append(base)\n",
        "    return pd.DataFrame(flat).sort_values(\"score_abs\", ascending=False)\n"
      ],
      "metadata": {
        "id": "0LH24sp-0Xyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 -\n",
        "\n",
        "print(\"\\n== Smoke tests (dry_run) ==\")\n",
        "tests = [\n",
        "    \"notaurl\",  # invalid\n",
        "    \"http://example.com/article\",  # non-eBay\n",
        "    \"https://www.ebay.com/itm/123\",  # eBay\n",
        "]\n",
        "for u in tests:\n",
        "    out = score_url(u, dry_run=True)\n",
        "    print(u, \"=>\", json.dumps(out[\"score\"], indent=2))\n",
        "\n",
        "print(\"\\n== Batch ranking (dry_run) ==\")\n",
        "ranked = rank_listings([tests[1], tests[2]], dry_run=True)\n",
        "for row in ranked:\n",
        "    print(row[\"url\"], row[\"score\"])\n",
        "\n",
        "if pd is not None:\n",
        "    df = to_dataframe(ranked)\n",
        "    display(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "f-cr-HRF0bW4",
        "outputId": "3fec1b08-d241-4411-a4f1-09bcf8d0f9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "== Smoke tests (dry_run) ==\n",
            "notaurl => {\n",
            "  \"absolute\": 0.0,\n",
            "  \"percentile\": null\n",
            "}\n",
            "http://example.com/article => {\n",
            "  \"absolute\": 7.82,\n",
            "  \"percentile\": null\n",
            "}\n",
            "https://www.ebay.com/itm/123 => {\n",
            "  \"absolute\": 39.94,\n",
            "  \"percentile\": null\n",
            "}\n",
            "\n",
            "== Batch ranking (dry_run) ==\n",
            "https://www.ebay.com/itm/123 {'absolute': 39.94, 'percentile': 100.0}\n",
            "http://example.com/article {'absolute': 7.82, 'percentile': 50.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                            url  score_abs  score_pct status          host  \\\n",
              "0  https://www.ebay.com/itm/123      39.94      100.0     ok  www.ebay.com   \n",
              "1    http://example.com/article       7.82       50.0     ok   example.com   \n",
              "\n",
              "   is_ebay  sig_domain_prior  sig_https  sig_content_length  \\\n",
              "0     True             0.070      0.040               0.014   \n",
              "1    False             0.042      0.016               0.014   \n",
              "\n",
              "   sig_citations_links  sig_author_block_hint  sig_sentiment  \\\n",
              "0                0.000                  0.015          0.025   \n",
              "1                0.008                  0.015            NaN   \n",
              "\n",
              "   sig_seller_feedback_pct  sig_seller_feedback_count  sig_top_rated  \\\n",
              "0                 0.119712                       0.08           0.06   \n",
              "1                      NaN                        NaN            NaN   \n",
              "\n",
              "   sig_returns_policy  sig_card_specificity_terms  sig_year_set_hint  \\\n",
              "0               0.046                      0.0952               0.06   \n",
              "1                 NaN                         NaN                NaN   \n",
              "\n",
              "   sig_image_count  sig_shipping_from  \n",
              "0           0.0375              0.021  \n",
              "1              NaN                NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6828630d-0234-499b-a586-1ecdad1274f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>score_abs</th>\n",
              "      <th>score_pct</th>\n",
              "      <th>status</th>\n",
              "      <th>host</th>\n",
              "      <th>is_ebay</th>\n",
              "      <th>sig_domain_prior</th>\n",
              "      <th>sig_https</th>\n",
              "      <th>sig_content_length</th>\n",
              "      <th>sig_citations_links</th>\n",
              "      <th>sig_author_block_hint</th>\n",
              "      <th>sig_sentiment</th>\n",
              "      <th>sig_seller_feedback_pct</th>\n",
              "      <th>sig_seller_feedback_count</th>\n",
              "      <th>sig_top_rated</th>\n",
              "      <th>sig_returns_policy</th>\n",
              "      <th>sig_card_specificity_terms</th>\n",
              "      <th>sig_year_set_hint</th>\n",
              "      <th>sig_image_count</th>\n",
              "      <th>sig_shipping_from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.ebay.com/itm/123</td>\n",
              "      <td>39.94</td>\n",
              "      <td>100.0</td>\n",
              "      <td>ok</td>\n",
              "      <td>www.ebay.com</td>\n",
              "      <td>True</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.119712</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.0952</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0375</td>\n",
              "      <td>0.021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://example.com/article</td>\n",
              "      <td>7.82</td>\n",
              "      <td>50.0</td>\n",
              "      <td>ok</td>\n",
              "      <td>example.com</td>\n",
              "      <td>False</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.015</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6828630d-0234-499b-a586-1ecdad1274f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6828630d-0234-499b-a586-1ecdad1274f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6828630d-0234-499b-a586-1ecdad1274f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5959544a-64d6-49f6-9709-4e4100845102\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5959544a-64d6-49f6-9709-4e4100845102')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5959544a-64d6-49f6-9709-4e4100845102 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"http://example.com/article\",\n          \"https://www.ebay.com/itm/123\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_abs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.712269811711906,\n        \"min\": 7.82,\n        \"max\": 39.94,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7.82,\n          39.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.35533905932738,\n        \"min\": 50.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"host\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"example.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_ebay\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_domain_prior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019798989873223326,\n        \"min\": 0.042,\n        \"max\": 0.06999999999999999,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.042\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_https\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01697056274847714,\n        \"min\": 0.016,\n        \"max\": 0.04,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_content_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.014000000000000002,\n        \"max\": 0.014000000000000002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.014000000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_citations_links\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00565685424949238,\n        \"min\": 0.0,\n        \"max\": 0.008,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_author_block_hint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.015,\n        \"max\": 0.015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.025,\n        \"max\": 0.025,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.025\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_seller_feedback_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.119712,\n        \"max\": 0.119712,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.119712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_seller_feedback_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.08,\n        \"max\": 0.08,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_top_rated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.06,\n        \"max\": 0.06,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_returns_policy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.046000000000000006,\n        \"max\": 0.046000000000000006,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.046000000000000006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_card_specificity_terms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0952,\n        \"max\": 0.0952,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_year_set_hint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.06,\n        \"max\": 0.06,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_image_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.037500000000000006,\n        \"max\": 0.037500000000000006,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.037500000000000006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_shipping_from\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.020999999999999998,\n        \"max\": 0.020999999999999998,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.020999999999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 -\n",
        "\n",
        "# --- Feature extractor: turn \"signals\" into a fixed vector ---\n",
        "FEATURE_ORDER = [\n",
        "    \"domain_prior\",\"https\",\"content_length\",\"citations_links\",\"author_block_hint\",\n",
        "    \"seller_feedback_pct\",\"seller_feedback_count\",\"top_rated\",\"returns_policy\",\n",
        "    \"card_specificity_terms\",\"year_set_hint\",\"image_count\",\"shipping_from\",\"sentiment\",\n",
        "]\n",
        "\n",
        "def signals_to_features(signals: list[dict]) -> dict[str, float]:\n",
        "    feats = {f: 0.0 for f in FEATURE_ORDER}\n",
        "    for s in signals:\n",
        "        feats[s[\"name\"]] = s[\"value\"] * s[\"weight\"]  # interpretable contribution\n",
        "    return feats\n",
        "\n",
        "def rows_to_matrix(rows: list[dict]):\n",
        "    X = []\n",
        "    for r in rows:\n",
        "        feats = signals_to_features(r[\"signals\"])\n",
        "        X.append([feats[f] for f in FEATURE_ORDER])\n",
        "    return np.array(X, dtype=float)\n",
        "\n",
        "# --- Calibration model (logistic regression) ---\n",
        "class Calibrator:\n",
        "    def __init__(self):\n",
        "        self.pipe = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"lr\", LogisticRegression(max_iter=200)),\n",
        "        ])\n",
        "        self.trained = False\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.pipe.fit(X, y)\n",
        "        self.trained = True\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        if not self.trained:\n",
        "            raise RuntimeError(\"Calibrator not trained.\")\n",
        "        return self.pipe.predict_proba(X)[:, 1]\n",
        "\n",
        "# --- Training data ---\n",
        "# Replace this demo block with your real labels when ready.\n",
        "have_sklearn = all(obj is not None for obj in (np, Pipeline, LogisticRegression, StandardScaler, train_test_split))\n",
        "if have_sklearn:\n",
        "    # Create a slightly larger demo set so both classes have >= 2 samples.\n",
        "    demo_urls = [\n",
        "        \"https://www.ebay.com/itm/111\",\n",
        "        \"https://www.ebay.com/itm/222\",\n",
        "        \"https://www.ebay.com/itm/333\",\n",
        "        \"http://example.com/article-a\",\n",
        "        \"http://example.org/article-b\",\n",
        "        \"http://example.net/article-c\",\n",
        "    ]\n",
        "    demo_rows = rank_listings(demo_urls, dry_run=True)\n",
        "    X = rows_to_matrix(demo_rows)\n",
        "\n",
        "    # Demo labels (placeholder!): treat eBay rows as 1, non-eBay as 0\n",
        "    y = np.array([1 if r[\"meta\"][\"is_ebay\"] else 0 for r in demo_rows], dtype=int)\n",
        "\n",
        "    # Check class counts\n",
        "    counts = np.bincount(y, minlength=2)\n",
        "    print(\"Class counts (demo):\", {cls: int(c) for cls, c in enumerate(counts)})\n",
        "\n",
        "    # Decide whether stratification is possible\n",
        "    can_stratify = counts.min() >= 2 and len(y) >= 4\n",
        "    stratify_arg = y if can_stratify else None\n",
        "    if not can_stratify:\n",
        "        print(\"Note: Not enough samples per class for stratified split; using non-stratified split.\")\n",
        "\n",
        "    # Train/validate split\n",
        "    Xtr, Xte, ytr, yte = train_test_split(\n",
        "        X, y, test_size=0.4, random_state=42, stratify=stratify_arg, shuffle=True\n",
        "    )\n",
        "    calib = Calibrator().fit(Xtr, ytr)\n",
        "    yhat = calib.predict_proba(Xte)\n",
        "    print(\"Calibration demo complete. Example predicted probs:\", np.round(yhat, 3))\n",
        "else:\n",
        "    print(\"sklearn/numpy not available; skip calibration demo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuOLmUyk1DRP",
        "outputId": "f567ca46-82a5-41d1-b348-6443a5dbbe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts (demo): {0: 3, 1: 3}\n",
            "Calibration demo complete. Example predicted probs: [0.073 0.124 0.952]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 -\n",
        "\n",
        "def blend_score(heuristic_abs: float, calibrated_prob: float | None) -> float:\n",
        "    \"\"\"\n",
        "    Blend heuristic 0..100 with calibrated prob 0..1 (if available).\n",
        "    Simple linear mix (70% heuristic, 30% calibrated). Tweak as desired.\n",
        "    \"\"\"\n",
        "    if calibrated_prob is None or not have_sklearn:\n",
        "        return heuristic_abs\n",
        "    return round(0.7 * heuristic_abs + 0.3 * (calibrated_prob * 100.0), 2)\n",
        "\n",
        "def score_url_with_calibration(\n",
        "    url: str,\n",
        "    *,\n",
        "    dry_run: bool = False,\n",
        "    calibrator: Calibrator | None = None,\n",
        ") -> dict:\n",
        "    base = score_url(url, dry_run=dry_run)\n",
        "    calibrated_prob = None\n",
        "    if calibrator is not None and have_sklearn:\n",
        "        feats = rows_to_matrix([base])  # uses base[\"signals\"] internally\n",
        "        # rows_to_matrix expects rows with [\"signals\"]; we wrap single base row\n",
        "        # but rows_to_matrix currently expects a list of dicts with signals list only\n",
        "        # So adapt minimally:\n",
        "        feats = np.array([[signals_to_features(base[\"signals\"])[f] for f in FEATURE_ORDER]], dtype=float)\n",
        "        calibrated_prob = float(calibrator.predict_proba(feats)[0])\n",
        "\n",
        "    blended = blend_score(base[\"score\"][\"absolute\"], calibrated_prob)\n",
        "    base[\"score\"][\"absolute\"] = blended\n",
        "    base[\"meta\"][\"calibrated_prob\"] = calibrated_prob\n",
        "    base[\"meta\"][\"version\"] = \"d2-0.1\"  # bump version to show calibration applied\n",
        "    return base\n",
        "\n",
        "# Demo (only if we trained calib above)\n",
        "if have_sklearn and 'calib' in globals() and isinstance(calib, Calibrator) and calib.trained:\n",
        "    demo = score_url_with_calibration(\"https://www.ebay.com/itm/456\", dry_run=True, calibrator=calib)\n",
        "    print(\"Blended score:\", demo[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwdcAIaX1LXd",
        "outputId": "e2be7587-0631-4683-bec8-0600e05e0a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blended score: {'absolute': 56.51, 'percentile': None}\n"
          ]
        }
      ]
    }
  ]
}