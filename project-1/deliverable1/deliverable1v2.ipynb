{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObhzep04+juDnpx69i6wbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-ferry/cs676-fall-2025/blob/main/project-1/deliverable1/deliverable1v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xe5eilhi2W5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credibility Scoring for eBay Soccer Card Listings in a RAG Chatbot"
      ],
      "metadata": {
        "id": "KjTKFJpkYRUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract\n",
        "We propose and evaluate a credibility scoring component for a Retrieval-Augmented Generation (RAG) chatbot that surfaces soccer card listings from eBay.  The system assigns a per-URL credibility score to help users judge the reliability of cited sources and prioritize higher-quality listing.  Our approach is hybrid: a transparent rule-based layer (domain/transport, content heuristics, and eBay-specific seller/listing signals) plus a lighweight ML calibration (logistic regression) that learns to reweight signal from labeled data.  We present the prototype algorithm, a stable JSON API, initial experiment and roadmap to production."
      ],
      "metadata": {
        "id": "e14kF-ssYays"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVGIARFGZ_XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction & Scope\n",
        "Large language models augemented with retrieval (RAG) can cite live source for pricing, comps, and context.  However, cited sources vary in reliability.  For sports cards on marketplaces like eBay, credibility as the likelihood that a liting accurately respresents what it claims (authenticity, condition clarity, seller reliability, sufficient evidence) and that it's a solid source to support chatbot responses.\n",
        "\n",
        "The report describes the design and evaluation of a credibility scorer that:\n",
        "\n",
        "\n",
        "*   Takes a URL as input\n",
        "*   Computes interpretable signals (domain prior seller feedback %, returns policy, specific/keywords, etc)\n",
        "*   Aggregates them into a 0-100 score, optionally calibrated via a small supervised model\n",
        "*   Returns a stable JSON the chatbot can display alongside citations.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KtgLxsB3YbgV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Problem Framing\n",
        "Goal: Assign each listing a credibility score useful for ranking and for user-facing explanation.\n",
        "\n",
        "Assumption:\n",
        "\n",
        "\n",
        "*   Seller reputation (feedback %, count, Top Rated) correlates with trust.\n",
        "*   Listings with clear photos, specific card attributes (grade, serial, set), and return policies are more reliable\n",
        "*   Very short or ambiguous descriptions reduce credibility\n",
        "*   Sentiment terms can be a weak prior (e.g. \"creased\", \"OC\", \"gem\", \"clean\")\n",
        "\n",
        "Next-steps:  We do not yet authenticate PSA certs, verify images, or compute fair market value.  These are roadmap items."
      ],
      "metadata": {
        "id": "fepTJ8DbafsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & Config\n",
        "\n",
        "# Purpose of this cell:\n",
        "# - Import only what we need for the core prototype to keep fast and stable\n",
        "# - Set conservaitve network defaults (timeouts/headers) so production integration goes smoother.\n",
        "# - Pre-compile a domain regex for eBay to enable platform-specific signals later.\n",
        "\n",
        "from __future__ import annotations\n",
        "# ^ Enables \"forward references\" for type hints (e.g., using a class/type name before it's defined)\n",
        "# Helps keep the file order flexible\n",
        "\n",
        "import dataclasses\n",
        "import json\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import typing as t\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime, timezone\n",
        "from urllib.parse import urlparse\n",
        "# ^ Standard-library imports only so far:\n",
        "# - cataclasses/dataclass: simple typed containers for signals and score results\n",
        "# - json: for serializing output/dicts\n",
        "# - math: numeric helpers (Log10, exp for squashing function)\n",
        "# - re: regular expressions for parsing text/html heuristics\n",
        "# - time: peformance timing (ms) for basic benchmarking/metadata\n",
        "# - typing: type hints, e.g., t.Sequence[float]\n",
        "# - datetime/timezone: timestamps in UTC (stable logging and reproducability)\n",
        "# - urllib.parse.urlparse: strict URL validation and parsing\n",
        "\n",
        "# Optional imports guarded at runtime; keep import-time light and notebook robust.\n",
        "try:\n",
        "    import requests  # HTTP client used only when dry_run=False\n",
        "except Exception:\n",
        "    requests = None  # # If requests isn't available (or blocked), we degrade gracefully.\n",
        "# ^ Rationale: Deliverable 1 must run even without network access (e.g., in Colab or CI).\n",
        "#   The code uses a \"dry_run\" mode that synthesizes HTML; this keeps tests deterministic.\n",
        "\n",
        "# Optional libs used later (pandas for tables; sklearn for D2 calibration)\n",
        "try:\n",
        "    import pandas as pd  # tabular display and simple data wrangling for ranked outputs\n",
        "except Exception:\n",
        "    pd = None # Allow notebook to run even if pandas isn't installed.\n",
        "\n",
        "try:\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import numpy as np\n",
        "except Exception:\n",
        "    LogisticRegression = None\n",
        "    Pipeline = None\n",
        "    StandardScaler = None\n",
        "    train_test_split = None\n",
        "    np = None\n",
        "\n",
        "# --- Network defaults (used only if dry_run=False) ---\n",
        "DEFAULT_TIMEOUT_S = 6.0\n",
        "# ^ Per-request timeout (seconds).  Conservative to avoid hanging UI calls.\n",
        "\n",
        "DEFAULT_HEADERS = {\n",
        "    # Custom UA string: polite + traceable in server logs; helps avoid some bot blocks.\n",
        "    \"User-Agent\": \"CredScorer/0.1 (+https://example.edu/project)\",\n",
        "    # Accept header: prefer HTML/XML; still accept anything to be resilient.\n",
        "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
        "}\n",
        "\n",
        "# --- Platform detector (precompiled regex) ---\n",
        "# Matches eBay primary domain and common regional TLDs (ebay.com, ebay.co.uk, ebay.de, etc.).\n",
        "EbayLike = re.compile(r\"(^|\\.)ebay\\.(com|co\\.[a-z]{2}|[a-z]{2})$\", re.I)\n"
      ],
      "metadata": {
        "id": "BjSRhuQfzrQw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f9_HjzBHcOZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2 — Data Structures & Stable Response Schema\n",
        "# -------------------------------------------------\n",
        "# Purpose:\n",
        "# 1) Define small, typed containers for signals and results (using dataclasses).\n",
        "# 2) Provide a *single stable* JSON contract via `response_json(...)` that every caller can rely on.\n",
        "#    This avoids brittle “if error, shape is different” problems when we integrate (Deliverable 3).\n",
        "\n",
        "@dataclass\n",
        "class Signal:\n",
        "    \"\"\"\n",
        "    An interpretable scoring *component* (feature) contributing to credibility.\n",
        "\n",
        "    Fields\n",
        "    ------\n",
        "    name : str\n",
        "        Short identifier (e.g., \"domain_prior\", \"seller_feedback_pct\").\n",
        "    value : float\n",
        "        Normalized feature value in [0, 1]. Higher is better (more credible/desirable).\n",
        "    weight : float\n",
        "        Weight in [0, 1] reflecting this signal's *influence* in the current heuristic model.\n",
        "        (In Deliverable 2, a learned model can reweight via calibration.)\n",
        "    rationale : str\n",
        "        Human-readable explanation so the UI/report can show *why* a score moved.\n",
        "    \"\"\"\n",
        "    name: str\n",
        "    value: float\n",
        "    weight: float\n",
        "    rationale: str\n",
        "\n",
        "    def contribution(self) -> float:\n",
        "        \"\"\"\n",
        "        Weighted contribution for this signal.\n",
        "        We keep the math simple and transparent: contribution = value * weight.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        float\n",
        "            Contribution in [0, 1] (typically small), later aggregated and squashed to [0, 100].\n",
        "        \"\"\"\n",
        "        return self.value * self.weight\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ScoreResult:\n",
        "    \"\"\"\n",
        "    Internal container for an entire scoring run on a single URL.\n",
        "    We keep this separate from the external JSON payload so we can evolve internals\n",
        "    without breaking the API contract.\n",
        "\n",
        "    Fields\n",
        "    ------\n",
        "    url : str\n",
        "        The URL that was evaluated.\n",
        "    status : str\n",
        "        \"ok\" for success; or \"invalid_url\", \"fetch_error\", etc. for graceful failure modes.\n",
        "    score_abs : float\n",
        "        Absolute score after aggregation and squashing to [0, 100].\n",
        "    score_pct : float | None\n",
        "        Optional percentile vs a cohort (if provided by batch ranking).\n",
        "    signals : list[Signal]\n",
        "        All computed signals with values/weights and rationales.\n",
        "    errors : list[str]\n",
        "        Non-fatal errors/warnings encountered (e.g., network timeouts).\n",
        "    meta : dict[str, t.Any]\n",
        "        Extra metadata (host, is_ebay flag, timestamps, timings, version tag).\n",
        "    \"\"\"\n",
        "    url: str\n",
        "    status: str\n",
        "    score_abs: float\n",
        "    score_pct: float | None\n",
        "    signals: list[Signal]\n",
        "    errors: list[str]\n",
        "    meta: dict[str, t.Any]\n",
        "\n",
        "\n",
        "def response_json(result: ScoreResult) -> dict:\n",
        "    \"\"\"\n",
        "    Convert internal ScoreResult into a *stable* JSON/dict that clients can consume.\n",
        "    This is the public contract for Deliverable 1/2/3. Keep this structure stable.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        {\n",
        "          \"url\": <str>,\n",
        "          \"status\": <\"ok\" | \"invalid_url\" | \"fetch_error\" | ...>,\n",
        "          \"score\": {\"absolute\": <float 0..100>, \"percentile\": <float|None>},\n",
        "          \"signals\": [{\"name\":..., \"value\":..., \"weight\":..., \"rationale\":...}, ...],\n",
        "          \"errors\": [<str>, ...],\n",
        "          \"meta\": { \"host\":..., \"is_ebay\":..., \"fetched_at\":..., \"elapsed_ms\":..., \"fetch_ms\":..., \"version\":\"d1-0.1\" }\n",
        "        }\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"url\": result.url,\n",
        "        \"status\": result.status,\n",
        "        \"score\": {\"absolute\": result.score_abs, \"percentile\": result.score_pct},\n",
        "        \"signals\": [dataclasses.asdict(s) for s in result.signals],\n",
        "        \"errors\": result.errors,\n",
        "        \"meta\": result.meta,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "mFmtQDti0Cj_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3 — Utilities\n",
        "# -------------------------------\n",
        "# Purpose: small helpers that are used everywhere else.\n",
        "# Keep them fast, deterministic, and side-effect free.\n",
        "\n",
        "def _cheap_text(html: str) -> str:\n",
        "    \"\"\"\n",
        "    Ultra-fast HTML → text stripper for heuristics.\n",
        "    We avoid BeautifulSoup to keep dependencies light and speed high.\n",
        "\n",
        "    Steps:\n",
        "      1) Remove <script> and <style> blocks (noise).\n",
        "      2) Remove all remaining HTML tags.\n",
        "      3) Collapse whitespace to single spaces.\n",
        "    Returns a plain text string suitable for regex/keyword scans.\n",
        "    \"\"\"\n",
        "    text = re.sub(r\"<script[\\s\\S]*?</script>\", \" \", html, flags=re.I)\n",
        "    text = re.sub(r\"<style[\\s\\S]*?</style>\", \" \", text, flags=re.I)\n",
        "    text = re.sub(r\"<[^>]+>\", \" \", text)       # strip tags\n",
        "    text = re.sub(r\"\\s+\", \" \", text)           # normalize whitespace\n",
        "    return text.strip()\n",
        "\n",
        "def _squash_0_100(raw: float) -> float:\n",
        "    \"\"\"\n",
        "    Map an unbounded-ish raw sum of contributions to a user-friendly 0..100 score\n",
        "    using a smooth logistic curve. Center around ~0.8 (typical moderate sum),\n",
        "    so small changes near the center are visible but extremes saturate.\n",
        "\n",
        "    raw: float, typically ~0..1.4 (sum of value*weight across signals)\n",
        "    \"\"\"\n",
        "    x = raw - 0.8\n",
        "    sig = 1 / (1 + math.exp(-3.5 * x))\n",
        "    return round(100 * sig, 2)\n",
        "\n",
        "def _percentile(x: float, arr: list[float]) -> float:\n",
        "    \"\"\"\n",
        "    Inclusive rank percentile in 0..100. If arr is empty, returns NaN.\n",
        "    We use a simple <= rank so ties are included.\n",
        "    \"\"\"\n",
        "    if not arr:\n",
        "        return float(\"nan\")\n",
        "    rank = sum(1 for a in arr if a <= x)\n",
        "    return round(100 * rank / len(arr), 2)\n",
        "\n",
        "def _now_iso() -> str:\n",
        "    \"\"\"UTC timestamp in ISO-8601 for reproducible logs/metadata.\"\"\"\n",
        "    return datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "def _elapsed_ms(t0: float) -> int:\n",
        "    \"\"\"Milliseconds elapsed since monotonic start t0 (from time.perf_counter()).\"\"\"\n",
        "    return int((time.perf_counter() - t0) * 1000)\n",
        "\n",
        "def _synthetic_page_for(host: str) -> str:\n",
        "    \"\"\"\n",
        "    Deterministic synthetic HTML used by dry_run=True.\n",
        "    Why: lets us test logic deterministically without network calls.\n",
        "\n",
        "    We emit an eBay-like snippet for eBay hosts, and a generic article otherwise.\n",
        "    \"\"\"\n",
        "    from re import compile, I\n",
        "    EbayLikeLocal = compile(r\"(^|\\.)ebay\\.(com|co\\.[a-z]{2}|[a-z]{2})$\", I)\n",
        "    if EbayLikeLocal.search(host or \"\"):\n",
        "        return (\n",
        "            \"<html><head><title>eBay Listing</title></head><body>\"\n",
        "            \"Top Rated Seller (99.7% positive feedback) (12450) feedback. \"\n",
        "            \"2024 Topps Chrome UEFA Refractor PSA 10 Rookie /99 auto. \"\n",
        "            \"Ships from New York. 30 day returns. <img/><img/><img/><img/><img/><img/>\"\n",
        "            \"</body></html>\"\n",
        "        )\n",
        "    return (\n",
        "        \"<html><body>By John Doe. Published 2023. References: https://doi.org/10.x/y \"\n",
        "        \"This is a sample article body with some length and structure.</body></html>\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "fPl4BW830MI_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4 - Generic, platform-agnostic signals\n",
        "# -------------------------------------------------------\n",
        "# These signals work for *any* URL and provide a transparent baseline.\n",
        "\n",
        "# Reuse the Signal class from Cell 2\n",
        "# from your_module import Signal  # (already defined in notebook)\n",
        "\n",
        "def _signal_domain_baseline(host: str) -> Signal:\n",
        "    \"\"\"\n",
        "    Small, interpretable prior based on the host's TLD/category.\n",
        "    Rationale: Certain domains (gov/edu) tend to have stronger editorial standards,\n",
        "    while eBay is a known marketplace with established buyer protections.\n",
        "    \"\"\"\n",
        "    h = (host or \"\").lower()\n",
        "    if h.endswith(\".gov\") or h.endswith(\".edu\"):\n",
        "        return Signal(\"domain_prior\", 0.90, 0.10, \"Academic/Gov domain prior\")\n",
        "    if h.endswith(\".org\"):\n",
        "        return Signal(\"domain_prior\", 0.75, 0.08, \".org prior (neutral-to-positive)\")\n",
        "    # Note: eBay handled again in eBay-specific signals, but we include a modest prior here.\n",
        "    from re import compile, I\n",
        "    if compile(r\"(^|\\.)ebay\\.(com|co\\.[a-z]{2}|[a-z]{2})$\", I).search(h):\n",
        "        return Signal(\"domain_prior\", 0.70, 0.10, \"Trusted marketplace host (eBay)\")\n",
        "    if h.endswith(\".com\"):\n",
        "        return Signal(\"domain_prior\", 0.60, 0.07, \".com baseline prior\")\n",
        "    return Signal(\"domain_prior\", 0.45, 0.05, \"Unknown/low-signal domain\")\n",
        "\n",
        "def _signal_transport_security(scheme: str) -> Signal:\n",
        "    \"\"\"\n",
        "    HTTPS is a soft trust signal (tamper-resistance in transit, modern hosting).\n",
        "    We don't over-weight it; just nudge up if https, down if http.\n",
        "    \"\"\"\n",
        "    return Signal(\n",
        "        \"https\",\n",
        "        1.0 if scheme == \"https\" else 0.4,\n",
        "        0.04,\n",
        "        \"HTTPS vs HTTP transport\",\n",
        "    )\n",
        "\n",
        "def _signals_content_quality(html: str) -> List[Signal]:\n",
        "    \"\"\"\n",
        "    Very lightweight text-based heuristics:\n",
        "      - Content length band (too short is suspect; too long is noisy).\n",
        "      - Outbound links/citations density (hints at sourcing).\n",
        "      - Author/date phrase hint (weak proxy for structured content).\n",
        "    These are intentionally conservative and interpretable.\n",
        "    \"\"\"\n",
        "    s: List[Signal] = []\n",
        "    text = _cheap_text(html)\n",
        "    n = len(text.split())\n",
        "\n",
        "    # Length band\n",
        "    if n <= 30:\n",
        "        v, why = 0.20, \"Very short body\"\n",
        "    elif n <= 120:\n",
        "        v, why = 0.55, \"Short body\"\n",
        "    elif n <= 2500:\n",
        "        v, why = 0.80, \"Reasonable body length\"\n",
        "    else:\n",
        "        v, why = 0.60, \"Very long body (diminishing returns)\"\n",
        "    s.append(Signal(\"content_length\", v, 0.07, why))\n",
        "\n",
        "    # Outbound refs/links density\n",
        "    cites = len(re.findall(r\"(doi\\.org/|https?://)\\S+\", text))\n",
        "    s.append(Signal(\"citations_links\", min(cites / 5, 1.0), 0.04, \"Outbound refs/links density\"))\n",
        "\n",
        "    # Author/date hint\n",
        "    has_authorish = bool(re.search(r\"\\bby\\s+[A-Z][a-z]+\", text))\n",
        "    s.append(Signal(\"author_block_hint\", 1.0 if has_authorish else 0.5, 0.03, \"Author/date block hints\"))\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "WwG_ZkO40Q1f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5 — eBay-specific signals + sentiment\n",
        "# --------------------------------------------------------------------\n",
        "# Purpose:\n",
        "#   Marketplace-aware features for eBay soccer card listings:\n",
        "#   seller reputation, returns, specificity (grading/serial/set), photos, sentiment.\n",
        "#   All signals are interpretable and combined as value * weight.\n",
        "\n",
        "# ---- Hobby lexicons (expand as needed) ----\n",
        "CARD_TERMS = {\n",
        "    # Rookie cues & desirability\n",
        "    \"rookie\": 0.12, \"rc\": 0.08,\n",
        "    # Grading\n",
        "    \"psa 10\": 0.16, \"bgs 9.5\": 0.10, \"sgc 10\": 0.08, \"gem mint\": 0.12,\n",
        "    # Auto/serial\n",
        "    \"auto\": 0.12, \"autograph\": 0.12, \"/\": 0.10,  # catches /10, /25, etc.\n",
        "    # Sets/variants\n",
        "    \"refractor\": 0.08, \"color match\": 0.10, \"prizm\": 0.08,\n",
        "    \"topps\": 0.06, \"merlin\": 0.06, \"select\": 0.06, \"optic\": 0.06,\n",
        "}\n",
        "\n",
        "_POS = {\n",
        "    \"grail\", \"pc\", \"beautiful\", \"clean\", \"crisp\", \"gem\", \"iconic\",\n",
        "    \"undervalued\", \"deal\", \"bargain\", \"goat\", \"legend\", \"heat\",\n",
        "}\n",
        "_NEG = {\n",
        "    \"creased\", \"damage\", \"ding\", \"scratches\", \"scratched\", \"off-center\",\n",
        "    \"offcenter\", \"trimmed\", \"fake\", \"reprint\", \"altered\", \"stain\",\n",
        "    \"worst\", \"overpriced\",\n",
        "}\n",
        "\n",
        "def sentiment_features(text: str) -> list[Signal]:\n",
        "    \"\"\"\n",
        "    Lightweight hobby sentiment (weak prior):\n",
        "      tokenize → count hits in _POS/_NEG → polarity in [-1,1] → map to [0,1].\n",
        "    \"\"\"\n",
        "    tokens = re.findall(r\"[a-zA-Z\\-]+\", text.lower())\n",
        "    pos_hits = sum(1 for w in tokens if w in _POS)\n",
        "    neg_hits = sum(1 for w in tokens if w in _NEG)\n",
        "    total = max(pos_hits + neg_hits, 1)\n",
        "    polarity = (pos_hits - neg_hits) / total          # [-1, 1]\n",
        "    val = (polarity + 1) / 2                          # [0, 1]\n",
        "    return [Signal(\"sentiment\", val, 0.05, f\"lexicon polarity {polarity:.2f}\")]\n",
        "\n",
        "def _signals_ebay_listing(html: str) -> list[Signal]:\n",
        "    \"\"\"\n",
        "    eBay-aware credibility heuristics for soccer card listings.\n",
        "\n",
        "    Signals:\n",
        "      seller_feedback_pct, seller_feedback_count, top_rated,\n",
        "      returns_policy, card_specificity_terms, year_set_hint,\n",
        "      image_count, shipping_from, sentiment.\n",
        "    \"\"\"\n",
        "    s: list[Signal] = []\n",
        "    text = _cheap_text(html)\n",
        "    lower = text.lower()\n",
        "\n",
        "    # Sentiment: small nudge, not decisive\n",
        "    s.extend(sentiment_features(text))\n",
        "\n",
        "    # Seller feedback %\n",
        "    m = re.search(r\"(\\d{1,3}\\.\\d)\\%\\s*positive feedback\", text, re.I)\n",
        "    if m:\n",
        "        pct = float(m.group(1))\n",
        "        v = 0.2 + 0.8 * (pct / 100.0)                # 0..100% → ~0.2..1.0\n",
        "        s.append(Signal(\"seller_feedback_pct\", min(v, 1.0), 0.12, f\"Seller feedback {pct}%\"))\n",
        "    else:\n",
        "        s.append(Signal(\"seller_feedback_pct\", 0.55, 0.06, \"Feedback % not found\"))\n",
        "\n",
        "    # Seller feedback count (log scale → diminishing returns)\n",
        "    m2 = re.search(r\"\\((\\d{2,6})\\)\\s*feedback\", text, re.I)\n",
        "    if m2:\n",
        "        cnt = int(m2.group(1))\n",
        "        v = min(math.log10(max(cnt, 1)) / 5.0 + 0.4, 1.0)\n",
        "        s.append(Signal(\"seller_feedback_count\", v, 0.08, f\"Feedback count {cnt}\"))\n",
        "\n",
        "    # Top Rated Seller badge\n",
        "    if re.search(r\"top rated seller\", text, re.I):\n",
        "        s.append(Signal(\"top_rated\", 1.0, 0.06, \"Top Rated Seller badge\"))\n",
        "\n",
        "    # Returns policy\n",
        "    if re.search(r\"\\b(30|60)\\s*day returns?\\b\", text, re.I):\n",
        "        s.append(Signal(\"returns_policy\", 0.92, 0.05, \"30/60-day returns\"))\n",
        "    elif re.search(r\"no returns\", text, re.I):\n",
        "        s.append(Signal(\"returns_policy\", 0.50, 0.05, \"No returns\"))\n",
        "\n",
        "    # Listing specificity: hobby keywords + jersey number hint\n",
        "    term_score = 0.0\n",
        "    for k, w in CARD_TERMS.items():\n",
        "        if k in lower:\n",
        "            term_score += w\n",
        "    if re.search(r\"\\b#?\\d{1,2}\\b\", lower):\n",
        "        term_score += 0.04\n",
        "    term_score = min(term_score, 1.0)\n",
        "    s.append(Signal(\"card_specificity_terms\", term_score, 0.14, \"Hobby keywords present\"))\n",
        "\n",
        "    # Year + Set mentioned\n",
        "    any_year = bool(re.search(r\"\\b(19|20)\\d{2}\\b\", text))\n",
        "    any_set  = bool(re.search(r\"(prizm|topps|merlin|select|optic|megacracks|chrome)\", lower))\n",
        "    s.append(Signal(\"year_set_hint\", 1.0 if (any_year and any_set) else 0.6, 0.06, \"Year+Set mentioned\"))\n",
        "\n",
        "    # Image count thoroughness proxy\n",
        "    imgs = len(re.findall(r\"<img\\b\", html, re.I))\n",
        "    if imgs >= 8:\n",
        "        s.append(Signal(\"image_count\", 0.95, 0.05, f\"{imgs} images\"))\n",
        "    elif imgs >= 4:\n",
        "        s.append(Signal(\"image_count\", 0.75, 0.05, f\"{imgs} images\"))\n",
        "    else:\n",
        "        s.append(Signal(\"image_count\", 0.55, 0.05, f\"{imgs} images\"))\n",
        "\n",
        "    # Shipping traceability\n",
        "    if re.search(r\"ships from\\s+[A-Za-z ]+\", lower):\n",
        "        s.append(Signal(\"shipping_from\", 0.70, 0.03, \"Ships-from present\"))\n",
        "\n",
        "    return s\n"
      ],
      "metadata": {
        "id": "ZDKqUzMO0UFn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 — Core scorer (score_url) & batch ranking (rank_listings)\n",
        "# ----------------------------------------------------------------\n",
        "# Purpose:\n",
        "#   - score_url(url): fetch (or synthesize), extract signals, aggregate to a 0..100 score,\n",
        "#                     and return a STABLE JSON payload for the chatbot/UI.\n",
        "#   - rank_listings(urls): score a batch, compute within-batch percentiles, return rows sorted by score.\n",
        "#\n",
        "# Design principles:\n",
        "#   1) Stable public contract: always return the same JSON keys (url, status, score, signals, errors, meta).\n",
        "#   2) Graceful degradation: handle invalid URLs, network failures, parser errors without crashing.\n",
        "#   3) Interpretability: surface per-signal rationales + contributions (value*weight) for explanations.\n",
        "#   4) Testability: dry_run=True uses deterministic synthetic HTML so smoke tests are stable and fast.\n",
        "\n",
        "def score_url(\n",
        "    url: str,\n",
        "    *,\n",
        "    dry_run: bool = False,\n",
        "    cohort_scores: t.Sequence[float] | None = None,\n",
        "    session: t.Any | None = None,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Evaluate one URL and return structured credibility JSON (public contract).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    url : str\n",
        "        The URL to evaluate (must include http/https and host).\n",
        "    dry_run : bool\n",
        "        If True, bypass network and use a synthetic HTML page (deterministic).\n",
        "    cohort_scores : Sequence[float] | None\n",
        "        Optional list of absolute scores from a peer cohort to compute a percentile.\n",
        "        (Used internally by rank_listings; you generally don't need to pass this.)\n",
        "    session : requests.Session | None\n",
        "        Optional HTTP session for connection reuse in batch mode.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        {\n",
        "          \"url\": <str>,\n",
        "          \"status\": \"ok\" | \"invalid_url\" | \"fetch_error\" | ...,\n",
        "          \"score\": {\"absolute\": <0..100>, \"percentile\": <float|None>},\n",
        "          \"signals\": [{\"name\":..., \"value\":..., \"weight\":..., \"rationale\":...}, ...],\n",
        "          \"errors\": [<str>, ...],\n",
        "          \"meta\": { \"host\":..., \"is_ebay\":..., \"fetched_at\":..., \"elapsed_ms\":..., \"fetch_ms\":..., \"version\":\"d1-0.1\" }\n",
        "        }\n",
        "    \"\"\"\n",
        "    t0 = time.perf_counter()\n",
        "    errors: list[str] = []\n",
        "    signals: list[Signal] = []\n",
        "\n",
        "    # ---- 1) URL validation & parse (fast fail if malformed) ----\n",
        "    try:\n",
        "        parsed = urlparse(url)\n",
        "        if parsed.scheme not in {\"http\", \"https\"} or not parsed.netloc:\n",
        "            raise ValueError(\"URL must include http(s) scheme and host\")\n",
        "        host = parsed.hostname or \"\"\n",
        "    except Exception as e:\n",
        "        # Keep contract stable even on error\n",
        "        result = ScoreResult(\n",
        "            url=url,\n",
        "            status=\"invalid_url\",\n",
        "            score_abs=0.0,\n",
        "            score_pct=None,\n",
        "            signals=[],\n",
        "            errors=[f\"invalid_url: {e}\"],\n",
        "            meta={\"fetched_at\": _now_iso(), \"elapsed_ms\": _elapsed_ms(t0)},\n",
        "        )\n",
        "        return response_json(result)\n",
        "\n",
        "    # ---- 2) Domain & transport priors (interpretable, cheap) ----\n",
        "    signals.append(_signal_domain_baseline(host))\n",
        "    signals.append(_signal_transport_security(parsed.scheme))\n",
        "\n",
        "    # ---- 3) Fetch content or synthesize (dry_run) ----\n",
        "    html: str | None = None\n",
        "    status: str = \"ok\"\n",
        "    fetched_ms = None\n",
        "\n",
        "    if dry_run:\n",
        "        # Deterministic synthetic pages: stable tests with no network dependency.\n",
        "        html = _synthetic_page_for(host)\n",
        "        fetched_ms = _elapsed_ms(t0)\n",
        "    else:\n",
        "        if requests is None:\n",
        "            # Environment without requests installed → degrade gracefully.\n",
        "            errors.append(\"requests_not_available\")\n",
        "            status = \"fetch_error\"\n",
        "        else:\n",
        "            try:\n",
        "                sess = session or requests.Session()\n",
        "                r = sess.get(url, headers=DEFAULT_HEADERS, timeout=DEFAULT_TIMEOUT_S)\n",
        "                fetched_ms = _elapsed_ms(t0)\n",
        "                if r.status_code >= 400:\n",
        "                    # Treat as fetch error but continue; signals so far still count.\n",
        "                    raise RuntimeError(f\"HTTP {r.status_code}\")\n",
        "                html = r.text\n",
        "            except Exception as e:\n",
        "                errors.append(f\"fetch_error: {e}\")\n",
        "                status = \"fetch_error\"\n",
        "\n",
        "    # ---- 4) Content & platform-specific signals (best effort) ----\n",
        "    if html:\n",
        "        try:\n",
        "            signals.extend(_signals_content_quality(html))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"content_parse_error: {e}\")\n",
        "        try:\n",
        "            # Add eBay-aware signals only for eBay-like hosts.\n",
        "            if EbayLike.search(host or \"\"):\n",
        "                signals.extend(_signals_ebay_listing(html))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"ebay_parse_error: {e}\")\n",
        "\n",
        "    # ---- 5) Aggregate to absolute score (0..100) ----\n",
        "    # Start from a simple, transparent sum of contributions.\n",
        "    raw = sum(s.contribution() for s in signals)\n",
        "    abs_score = _squash_0_100(raw)   # logistic squash to a user-friendly 0..100\n",
        "\n",
        "    # ---- 6) Optional percentile vs cohort (if provided) ----\n",
        "    pct = None\n",
        "    if cohort_scores:\n",
        "        try:\n",
        "            pct = _percentile(abs_score, list(cohort_scores))\n",
        "        except Exception as e:\n",
        "            errors.append(f\"percentile_error: {e}\")\n",
        "\n",
        "    # ---- 7) Assemble the stable JSON payload ----\n",
        "    result = ScoreResult(\n",
        "        url=url,\n",
        "        status=status,\n",
        "        score_abs=abs_score,\n",
        "        score_pct=pct,\n",
        "        signals=signals,\n",
        "        errors=errors,\n",
        "        meta={\n",
        "            \"host\": host,\n",
        "            \"is_ebay\": bool(EbayLike.search(host or \"\")),\n",
        "            \"fetched_at\": _now_iso(),\n",
        "            \"elapsed_ms\": _elapsed_ms(t0),  # end-to-end latency\n",
        "            \"fetch_ms\": fetched_ms,         # time until bytes received (if fetched)\n",
        "            \"version\": \"d1-0.1\",            # bump when adding new fields/semantics\n",
        "        },\n",
        "    )\n",
        "    return response_json(result)\n",
        "\n",
        "\n",
        "def rank_listings(urls: list[str], *, dry_run: bool = False) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Score a list of URLs, attach within-batch percentiles, and return rows sorted by score desc.\n",
        "\n",
        "    Implementation details:\n",
        "    - Uses a shared HTTP session (when not dry_run) for connection reuse → faster batches.\n",
        "    - Two-pass approach:\n",
        "        (1) score each URL and collect absolute scores;\n",
        "        (2) compute percentile for each row within the cohort and attach to the row.\n",
        "    \"\"\"\n",
        "    rows: list[dict] = []\n",
        "    sess = None if dry_run else (requests.Session() if requests else None)\n",
        "\n",
        "    # First pass: get absolute scores\n",
        "    tmp: list[dict] = []\n",
        "    abs_scores: list[float] = []\n",
        "    for u in urls:\n",
        "        r = score_url(u, dry_run=dry_run, session=sess)\n",
        "        tmp.append(r)\n",
        "        abs_scores.append(r[\"score\"][\"absolute\"])\n",
        "\n",
        "    # Second pass: compute percentiles in-batch\n",
        "    for r in tmp:\n",
        "        r[\"score\"][\"percentile\"] = _percentile(r[\"score\"][\"absolute\"], abs_scores)\n",
        "        rows.append(r)\n",
        "\n",
        "    # Sort best-to-worst by absolute score\n",
        "    rows.sort(key=lambda d: d[\"score\"][\"absolute\"], reverse=True)\n",
        "    return rows\n",
        "\n",
        "\n",
        "def to_dataframe(rows: list[dict]):\n",
        "    \"\"\"\n",
        "    Convenience: convert ranked rows to a tidy DataFrame for analysis/plots.\n",
        "    Requires pandas. Each signal's contribution is expanded as a column.\n",
        "    \"\"\"\n",
        "    if pd is None:\n",
        "        raise RuntimeError(\"pandas not installed\")\n",
        "    flat = []\n",
        "    for r in rows:\n",
        "        base = {\n",
        "            \"url\": r[\"url\"],\n",
        "            \"score_abs\": r[\"score\"][\"absolute\"],\n",
        "            \"score_pct\": r[\"score\"].get(\"percentile\"),\n",
        "            \"status\": r[\"status\"],\n",
        "            \"host\": r[\"meta\"].get(\"host\"),\n",
        "            \"is_ebay\": r[\"meta\"].get(\"is_ebay\"),\n",
        "        }\n",
        "        # Expand signal contributions as features (good for calibration & analysis)\n",
        "        for sig in r[\"signals\"]:\n",
        "            base[f\"sig_{sig['name']}\"] = sig[\"value\"] * sig[\"weight\"]\n",
        "        flat.append(base)\n",
        "    return pd.DataFrame(flat).sort_values(\"score_abs\", ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "0LH24sp-0Xyv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Smoke Tests (Functional Sanity)\n",
        "These tests validate that the scorer runs end-to-end, returns a stable JSON shape, and produces plausible scores without network access.\n"
      ],
      "metadata": {
        "id": "tSQGSsGOlTqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7 — Smoke Tests & Demo\n",
        "# ---------------------------\n",
        "# Purpose:\n",
        "#   Quick, shallow checks that the system runs end-to-end and returns plausible,\n",
        "#   well-formed JSON — without relying on the network (dry_run=True).\n",
        "\n",
        "# Minimal test corpus:\n",
        "tests = [\n",
        "    \"notaurl\",                          # invalid URL → should return status=\"invalid_url\"\n",
        "    \"http://example.com/article\",       # generic (non-eBay) page → generic signals only\n",
        "    \"https://www.ebay.com/itm/123\",     # eBay listing → adds eBay-specific signals\n",
        "]\n",
        "\n",
        "def top_signals(sig_list, k=5):\n",
        "    \"\"\"Return top-k signals by contribution (value*weight), descending.\"\"\"\n",
        "    return sorted(\n",
        "        sig_list,\n",
        "        key=lambda s: s[\"value\"] * s[\"weight\"],\n",
        "        reverse=True\n",
        "    )[:k]\n",
        "\n",
        "print(\"== Smoke tests (dry_run=True, no network) ==\")\n",
        "for u in tests:\n",
        "    out = score_url(u, dry_run=True)\n",
        "    # Contract sanity: should always have these keys\n",
        "    assert {\"url\",\"status\",\"score\",\"signals\",\"errors\",\"meta\"} <= set(out), \"Response schema mismatch\"\n",
        "    print(f\"\\nURL: {u}\")\n",
        "    print(\"  status:\", out[\"status\"])\n",
        "    print(\"  score:\", out[\"score\"])  # {\"absolute\": .., \"percentile\": None}\n",
        "    if out[\"errors\"]:\n",
        "        print(\"  errors:\", out[\"errors\"])\n",
        "    # Show top-3 contributing signals to keep output compact\n",
        "    ts = top_signals(out[\"signals\"], k=3)\n",
        "    print(\"  top_signals:\")\n",
        "    for s in ts:\n",
        "        print(f\"    - {s['name']}: value={s['value']:.2f}, weight={s['weight']:.2f}, contrib={(s['value']*s['weight']):.3f}\")\n",
        "\n",
        "print(\"\\n== Batch ranking demo (dry_run) ==\")\n",
        "ranked = rank_listings([tests[1], tests[2]], dry_run=True)\n",
        "for row in ranked:\n",
        "    print(f\"URL: {row['url']}\")\n",
        "    print(\"  score:\", row[\"score\"])  # now includes a percentile within this small batch\n",
        "    print(\"  status:\", row[\"status\"])\n",
        "\n",
        "# Optional: compact table if pandas is available\n",
        "if pd is not None:\n",
        "    print(\"\\n== Ranked table (top rows) ==\")\n",
        "    df = to_dataframe(ranked)\n",
        "    display(df.head(10)[[\n",
        "        \"url\",\"score_abs\",\"score_pct\",\n",
        "        # a few signal columns (add/remove as you like)\n",
        "        \"sig_domain_prior\",\"sig_https\",\"sig_content_length\",\"sig_card_specificity_terms\",\"sig_seller_feedback_pct\"\n",
        "    ]].fillna(\"\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "f-cr-HRF0bW4",
        "outputId": "f8a701c6-49cd-4102-8dc6-8e6179a039db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Smoke tests (dry_run=True, no network) ==\n",
            "\n",
            "URL: notaurl\n",
            "  status: invalid_url\n",
            "  score: {'absolute': 0.0, 'percentile': None}\n",
            "  errors: ['invalid_url: URL must include http(s) scheme and host']\n",
            "  top_signals:\n",
            "\n",
            "URL: http://example.com/article\n",
            "  status: ok\n",
            "  score: {'absolute': 7.82, 'percentile': None}\n",
            "  top_signals:\n",
            "    - domain_prior: value=0.60, weight=0.07, contrib=0.042\n",
            "    - https: value=0.40, weight=0.04, contrib=0.016\n",
            "    - author_block_hint: value=0.50, weight=0.03, contrib=0.015\n",
            "\n",
            "URL: https://www.ebay.com/itm/123\n",
            "  status: ok\n",
            "  score: {'absolute': 39.94, 'percentile': None}\n",
            "  top_signals:\n",
            "    - seller_feedback_pct: value=1.00, weight=0.12, contrib=0.120\n",
            "    - card_specificity_terms: value=0.68, weight=0.14, contrib=0.095\n",
            "    - seller_feedback_count: value=1.00, weight=0.08, contrib=0.080\n",
            "\n",
            "== Batch ranking demo (dry_run) ==\n",
            "URL: https://www.ebay.com/itm/123\n",
            "  score: {'absolute': 39.94, 'percentile': 100.0}\n",
            "  status: ok\n",
            "URL: http://example.com/article\n",
            "  score: {'absolute': 7.82, 'percentile': 50.0}\n",
            "  status: ok\n",
            "\n",
            "== Ranked table (top rows) ==\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                            url  score_abs  score_pct  sig_domain_prior  \\\n",
              "0  https://www.ebay.com/itm/123      39.94      100.0             0.070   \n",
              "1    http://example.com/article       7.82       50.0             0.042   \n",
              "\n",
              "   sig_https  sig_content_length sig_card_specificity_terms  \\\n",
              "0      0.040               0.014                     0.0952   \n",
              "1      0.016               0.014                              \n",
              "\n",
              "  sig_seller_feedback_pct  \n",
              "0                0.119712  \n",
              "1                          "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cbcee6d-9175-4c7b-9bb8-43e17ff18344\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>score_abs</th>\n",
              "      <th>score_pct</th>\n",
              "      <th>sig_domain_prior</th>\n",
              "      <th>sig_https</th>\n",
              "      <th>sig_content_length</th>\n",
              "      <th>sig_card_specificity_terms</th>\n",
              "      <th>sig_seller_feedback_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.ebay.com/itm/123</td>\n",
              "      <td>39.94</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.070</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.0952</td>\n",
              "      <td>0.119712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://example.com/article</td>\n",
              "      <td>7.82</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.042</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.014</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cbcee6d-9175-4c7b-9bb8-43e17ff18344')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cbcee6d-9175-4c7b-9bb8-43e17ff18344 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cbcee6d-9175-4c7b-9bb8-43e17ff18344');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c70eaff-e8ae-4c71-bcca-d9ffaf2bc917\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c70eaff-e8ae-4c71-bcca-d9ffaf2bc917')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c70eaff-e8ae-4c71-bcca-d9ffaf2bc917 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    ]]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"http://example.com/article\",\n          \"https://www.ebay.com/itm/123\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_abs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.712269811711906,\n        \"min\": 7.82,\n        \"max\": 39.94,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7.82,\n          39.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.35533905932738,\n        \"min\": 50.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          50.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_domain_prior\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019798989873223326,\n        \"min\": 0.042,\n        \"max\": 0.06999999999999999,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.042,\n          0.06999999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_https\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01697056274847714,\n        \"min\": 0.016,\n        \"max\": 0.04,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.016,\n          0.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_content_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.014000000000000002,\n        \"max\": 0.014000000000000002,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.014000000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_card_specificity_terms\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00\",\n        \"max\": \"1970-01-01 00:00:00\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sig_seller_feedback_pct\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00\",\n        \"max\": \"1970-01-01 00:00:00\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Smoke tests. All three cases returned the stable response schema (url,status,score,signals,errors,meta) with no exceptions. The synthetic eBay page shows marketplace-specific signals among the top contributors (seller feedback %, listing specificity). Batch ranking produced correct within-batch percentiles. These checks confirm the end-to-end pipeline and output contract prior to calibration."
      ],
      "metadata": {
        "id": "DGZll4UxoR0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8 -\n",
        "\n",
        "# --- Feature extractor: turn \"signals\" into a fixed vector ---\n",
        "FEATURE_ORDER = [\n",
        "    \"domain_prior\",\"https\",\"content_length\",\"citations_links\",\"author_block_hint\",\n",
        "    \"seller_feedback_pct\",\"seller_feedback_count\",\"top_rated\",\"returns_policy\",\n",
        "    \"card_specificity_terms\",\"year_set_hint\",\"image_count\",\"shipping_from\",\"sentiment\",\n",
        "]\n",
        "\n",
        "def signals_to_features(signals: list[dict]) -> dict[str, float]:\n",
        "    feats = {f: 0.0 for f in FEATURE_ORDER}\n",
        "    for s in signals:\n",
        "        feats[s[\"name\"]] = s[\"value\"] * s[\"weight\"]  # interpretable contribution\n",
        "    return feats\n",
        "\n",
        "def rows_to_matrix(rows: list[dict]):\n",
        "    X = []\n",
        "    for r in rows:\n",
        "        feats = signals_to_features(r[\"signals\"])\n",
        "        X.append([feats[f] for f in FEATURE_ORDER])\n",
        "    return np.array(X, dtype=float)\n",
        "\n",
        "# --- Calibration model (logistic regression) ---\n",
        "class Calibrator:\n",
        "    def __init__(self):\n",
        "        self.pipe = Pipeline([\n",
        "            (\"scaler\", StandardScaler()),\n",
        "            (\"lr\", LogisticRegression(max_iter=200)),\n",
        "        ])\n",
        "        self.trained = False\n",
        "\n",
        "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.pipe.fit(X, y)\n",
        "        self.trained = True\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
        "        if not self.trained:\n",
        "            raise RuntimeError(\"Calibrator not trained.\")\n",
        "        return self.pipe.predict_proba(X)[:, 1]\n",
        "\n",
        "# --- Training data ---\n",
        "# Replace this demo block with your real labels when ready.\n",
        "have_sklearn = all(obj is not None for obj in (np, Pipeline, LogisticRegression, StandardScaler, train_test_split))\n",
        "if have_sklearn:\n",
        "    # Create a slightly larger demo set so both classes have >= 2 samples.\n",
        "    demo_urls = [\n",
        "        \"https://www.ebay.com/itm/111\",\n",
        "        \"https://www.ebay.com/itm/222\",\n",
        "        \"https://www.ebay.com/itm/333\",\n",
        "        \"http://example.com/article-a\",\n",
        "        \"http://example.org/article-b\",\n",
        "        \"http://example.net/article-c\",\n",
        "    ]\n",
        "    demo_rows = rank_listings(demo_urls, dry_run=True)\n",
        "    X = rows_to_matrix(demo_rows)\n",
        "\n",
        "    # Demo labels (placeholder!): treat eBay rows as 1, non-eBay as 0\n",
        "    y = np.array([1 if r[\"meta\"][\"is_ebay\"] else 0 for r in demo_rows], dtype=int)\n",
        "\n",
        "    # Check class counts\n",
        "    counts = np.bincount(y, minlength=2)\n",
        "    print(\"Class counts (demo):\", {cls: int(c) for cls, c in enumerate(counts)})\n",
        "\n",
        "    # Decide whether stratification is possible\n",
        "    can_stratify = counts.min() >= 2 and len(y) >= 4\n",
        "    stratify_arg = y if can_stratify else None\n",
        "    if not can_stratify:\n",
        "        print(\"Note: Not enough samples per class for stratified split; using non-stratified split.\")\n",
        "\n",
        "    # Train/validate split\n",
        "    Xtr, Xte, ytr, yte = train_test_split(\n",
        "        X, y, test_size=0.4, random_state=42, stratify=stratify_arg, shuffle=True\n",
        "    )\n",
        "    calib = Calibrator().fit(Xtr, ytr)\n",
        "    yhat = calib.predict_proba(Xte)\n",
        "    print(\"Calibration demo complete. Example predicted probs:\", np.round(yhat, 3))\n",
        "else:\n",
        "    print(\"sklearn/numpy not available; skip calibration demo.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuOLmUyk1DRP",
        "outputId": "f567ca46-82a5-41d1-b348-6443a5dbbe26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts (demo): {0: 3, 1: 3}\n",
            "Calibration demo complete. Example predicted probs: [0.073 0.124 0.952]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9 -\n",
        "\n",
        "def blend_score(heuristic_abs: float, calibrated_prob: float | None) -> float:\n",
        "    \"\"\"\n",
        "    Blend heuristic 0..100 with calibrated prob 0..1 (if available).\n",
        "    Simple linear mix (70% heuristic, 30% calibrated). Tweak as desired.\n",
        "    \"\"\"\n",
        "    if calibrated_prob is None or not have_sklearn:\n",
        "        return heuristic_abs\n",
        "    return round(0.7 * heuristic_abs + 0.3 * (calibrated_prob * 100.0), 2)\n",
        "\n",
        "def score_url_with_calibration(\n",
        "    url: str,\n",
        "    *,\n",
        "    dry_run: bool = False,\n",
        "    calibrator: Calibrator | None = None,\n",
        ") -> dict:\n",
        "    base = score_url(url, dry_run=dry_run)\n",
        "    calibrated_prob = None\n",
        "    if calibrator is not None and have_sklearn:\n",
        "        feats = rows_to_matrix([base])  # uses base[\"signals\"] internally\n",
        "        # rows_to_matrix expects rows with [\"signals\"]; we wrap single base row\n",
        "        # but rows_to_matrix currently expects a list of dicts with signals list only\n",
        "        # So adapt minimally:\n",
        "        feats = np.array([[signals_to_features(base[\"signals\"])[f] for f in FEATURE_ORDER]], dtype=float)\n",
        "        calibrated_prob = float(calibrator.predict_proba(feats)[0])\n",
        "\n",
        "    blended = blend_score(base[\"score\"][\"absolute\"], calibrated_prob)\n",
        "    base[\"score\"][\"absolute\"] = blended\n",
        "    base[\"meta\"][\"calibrated_prob\"] = calibrated_prob\n",
        "    base[\"meta\"][\"version\"] = \"d2-0.1\"  # bump version to show calibration applied\n",
        "    return base\n",
        "\n",
        "# Demo (only if we trained calib above)\n",
        "if have_sklearn and 'calib' in globals() and isinstance(calib, Calibrator) and calib.trained:\n",
        "    demo = score_url_with_calibration(\"https://www.ebay.com/itm/456\", dry_run=True, calibrator=calib)\n",
        "    print(\"Blended score:\", demo[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwdcAIaX1LXd",
        "outputId": "e2be7587-0631-4683-bec8-0600e05e0a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blended score: {'absolute': 56.51, 'percentile': None}\n"
          ]
        }
      ]
    }
  ]
}